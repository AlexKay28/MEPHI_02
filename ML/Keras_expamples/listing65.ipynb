{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The': 1,\n",
       " 'cat': 2,\n",
       " 'sat': 3,\n",
       " 'on': 4,\n",
       " 'the': 5,\n",
       " 'mat.': 6,\n",
       " 'dog': 7,\n",
       " 'ate': 8,\n",
       " 'my': 9,\n",
       " 'work.': 10}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "samples = ['The cat sat on the mat.',\n",
    "           'The dog ate my work.']\n",
    "\n",
    "token_index = {}\n",
    "for sample in samples:\n",
    "    for word in sample.split():\n",
    "        if word not in token_index:\n",
    "            token_index[word] = len(token_index)+1\n",
    "token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lenght = 10\n",
    "results = np.zeros(shape=(len(samples),\n",
    "                    max_lenght,\n",
    "                    max(token_index.values()) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_lenght]:\n",
    "        index = token_index.get(word)\n",
    "        results[i,j,index] = 1\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(samples)\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "emb_layer = Embedding(1000,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "\n",
    "max_features = 10_000\n",
    "maxlen = 40\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  22,   21,  134, ...,   19,  178,   32],\n",
       "        [ 152,  491,   18, ...,   16,  145,   95],\n",
       "        [  23,   22,   12, ...,    7,  129,  113],\n",
       "        ...,\n",
       "        [ 234, 2766,  234, ...,    4, 3586,    2],\n",
       "        [  14,  123,    5, ...,   12,    9,   23],\n",
       "        [1468,    2,  497, ...,  204,  131,    9]], dtype=int32),\n",
       " array([[  13,   92,  124, ...,   14,    6,  717],\n",
       "        [   4,  529,   48, ...,  125,    4, 3077],\n",
       "        [2321,   42, 1898, ...,    9,   57,  975],\n",
       "        ...,\n",
       "        [   4,  116,  218, ...,   21,  846, 5518],\n",
       "        [ 985,  200,    5, ..., 2302,    7,  470],\n",
       "        [  11,    4, 3567, ...,   34, 2005, 2643]], dtype=int32))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 40, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 321       \n",
      "=================================================================\n",
      "Total params: 80,321\n",
      "Trainable params: 80,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 8, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy',\n",
    "                 metrics = ['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexkay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 71us/step - loss: 0.6558 - acc: 0.6404 - val_loss: 0.5700 - val_acc: 0.7398\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.4775 - acc: 0.7926 - val_loss: 0.4586 - val_acc: 0.7790\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 1s 64us/step - loss: 0.3901 - acc: 0.8274 - val_loss: 0.4318 - val_acc: 0.7956\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.3508 - acc: 0.8455 - val_loss: 0.4249 - val_acc: 0.7982\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.3245 - acc: 0.8604 - val_loss: 0.4279 - val_acc: 0.7970\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.3034 - acc: 0.8726 - val_loss: 0.4304 - val_acc: 0.7960\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 1s 64us/step - loss: 0.2844 - acc: 0.8819 - val_loss: 0.4371 - val_acc: 0.7940\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 1s 68us/step - loss: 0.2669 - acc: 0.8905 - val_loss: 0.4401 - val_acc: 0.7940\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.2501 - acc: 0.8993 - val_loss: 0.4474 - val_acc: 0.7972\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 1s 64us/step - loss: 0.2339 - acc: 0.9074 - val_loss: 0.4587 - val_acc: 0.7940\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-8a344a3399e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'plot'"
     ]
    }
   ],
   "source": [
    "history.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
